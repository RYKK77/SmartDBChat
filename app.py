import streamlit as st
import mysql.connector
from openai import OpenAI
from typing import List, Dict
import json
import pandas as pd
import plotly.express as px
import sqlite3
import hashlib
import requests
from datetime import datetime, timedelta

from pygments.lexers import go


class SemanticQueryCache:
    def __init__(self, cache_db_path="semantic_cache.db", similarity_threshold=0.85):
        """åˆå§‹åŒ–è¯­ä¹‰æŸ¥è¯¢ç¼“å­˜ç³»ç»Ÿ"""
        self.cache_db_path = cache_db_path
        self.similarity_threshold = similarity_threshold
        self.client = None  # å°†åœ¨éœ€è¦æ—¶åˆå§‹åŒ–
        self.embedding_available = True  # æ ‡è®°åµŒå…¥APIæ˜¯å¦å¯ç”¨
        self._init_cache_db()
        self.base_embedding_url = "http://localhost:11434"  # åœ¨è¿™é‡Œå®šä¹‰base_url

    def set_api_client(self, client):
        """è®¾ç½®APIå®¢æˆ·ç«¯"""
        self.client = client
        # æµ‹è¯•åµŒå…¥APIæ˜¯å¦å¯ç”¨
        self._test_embedding_availability()

    def _test_embedding_availability(self):
        """æµ‹è¯•åµŒå…¥APIæ˜¯å¦å¯ç”¨"""
        try:
            test_embedding = self._get_embedding("æµ‹è¯•")
            self.embedding_available = test_embedding is not None
            if not self.embedding_available:
                st.warning("åµŒå…¥å‘é‡APIä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å¤‡é€‰æ–‡æœ¬ç›¸ä¼¼åº¦ç®—æ³•")
        except Exception as e:
            self.embedding_available = False
            st.warning(f"åµŒå…¥å‘é‡APIæµ‹è¯•å¤±è´¥: {str(e)}ï¼Œå°†ä½¿ç”¨å¤‡é€‰æ–‡æœ¬ç›¸ä¼¼åº¦ç®—æ³•")

    def _init_cache_db(self):
        """åˆå§‹åŒ–ç¼“å­˜æ•°æ®åº“"""
        conn = sqlite3.connect(self.cache_db_path)
        cursor = conn.cursor()

        # ä¿®æ”¹ç¼“å­˜è¡¨ç»“æ„ï¼Œç§»é™¤ä¸éœ€è¦çš„å­—æ®µï¼Œåªä¿ç•™SQLç›¸å…³ä¿¡æ¯
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS query_cache (
            query_hash TEXT PRIMARY KEY,
            query_text TEXT,
            query_embedding TEXT,  -- å­˜å‚¨ä¸ºJSONå­—ç¬¦ä¸²
            db_name TEXT,
            sql TEXT,
            created_at TIMESTAMP,
            accessed_at TIMESTAMP,
            access_count INTEGER
        )
        ''')

        conn.commit()
        conn.close()

    def _generate_hash(self, query, db_name):
        """ä¸ºæŸ¥è¯¢ç”Ÿæˆå”¯ä¸€å“ˆå¸Œå€¼"""
        hash_input = f"{query}:{db_name}"
        return hashlib.md5(hash_input.encode()).hexdigest()

    def _get_embedding(self, text):
        """è·å–æ–‡æœ¬çš„åµŒå…¥å‘é‡"""
        if not self.client:
            st.warning("APIå®¢æˆ·ç«¯æœªè®¾ç½®ï¼Œæ— æ³•è·å–åµŒå…¥å‘é‡")
            return None

        try:
            # ä½¿ç”¨Ollama APIè·å–åµŒå…¥å‘é‡
            response = requests.post(
                f"{self.base_embedding_url}/api/embeddings",
                json={
                    "model": "nomic-embed-text",  # Ollamaçš„åµŒå…¥æ¨¡å‹
                    "prompt": text
                }
            )

            if response.status_code == 200:
                embedding_data = response.json()
                return embedding_data["embedding"]
            else:
                st.warning(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return None

        except Exception as e:
            st.warning(f"è·å–åµŒå…¥å‘é‡å¤±è´¥: {str(e)}")
            return None

    def _find_similar_query(self, query, db_name):
        """æŸ¥æ‰¾è¯­ä¹‰ç›¸ä¼¼çš„æŸ¥è¯¢"""
        # å¦‚æœåµŒå…¥APIå¯ç”¨ï¼Œä½¿ç”¨åµŒå…¥å‘é‡è®¡ç®—ç›¸ä¼¼åº¦
        if self.embedding_available and self.client:
            # è·å–å½“å‰æŸ¥è¯¢çš„åµŒå…¥å‘é‡
            query_embedding = self._get_embedding(query)
            if query_embedding:
                # ä»æ•°æ®åº“è·å–æ‰€æœ‰æŸ¥è¯¢åŠå…¶åµŒå…¥å‘é‡
                conn = sqlite3.connect(self.cache_db_path)
                cursor = conn.cursor()

                cursor.execute(
                    "SELECT query_hash, query_text, query_embedding FROM query_cache WHERE db_name = ?",
                    (db_name,)
                )
                cached_queries = cursor.fetchall()
                conn.close()

                if not cached_queries:
                    return None

                # è®¡ç®—ç›¸ä¼¼åº¦å¹¶æ‰¾å‡ºæœ€ç›¸ä¼¼çš„æŸ¥è¯¢
                max_similarity = 0
                most_similar_hash = None

                for query_hash, query_text, embedding_json in cached_queries:
                    if not embedding_json:
                        continue

                    try:
                        cached_embedding = json.loads(embedding_json)
                        similarity = self._cosine_similarity(query_embedding, cached_embedding)

                        if similarity > max_similarity:
                            max_similarity = similarity
                            most_similar_hash = query_hash
                    except Exception as e:
                        continue

                # å¦‚æœç›¸ä¼¼åº¦è¶…è¿‡é˜ˆå€¼ï¼Œè¿”å›æœ€ç›¸ä¼¼æŸ¥è¯¢çš„å“ˆå¸Œå€¼
                if max_similarity >= self.similarity_threshold:
                    st.info(f"æ‰¾åˆ°ç›¸ä¼¼é—®é¢˜ï¼Œç›¸ä¼¼åº¦: {max_similarity:.2f}")
                    return most_similar_hash

                return None

        # å¦‚æœåµŒå…¥APIä¸å¯ç”¨æˆ–è·å–å¤±è´¥ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ
        return self._find_similar_query_fallback(query, db_name)

    def _cosine_similarity(self, vec1, vec2):
        """è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦"""
        try:
            import numpy as np
            vec1 = np.array(vec1)
            vec2 = np.array(vec2)
            return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
        except Exception as e:
            st.warning(f"è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦å¤±è´¥: {str(e)}")
            return 0

    def _find_similar_query_fallback(self, query, db_name):
        """å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—æŸ¥æ‰¾ç›¸ä¼¼æŸ¥è¯¢"""
        try:
            # ä»æ•°æ®åº“è·å–æ‰€æœ‰æŸ¥è¯¢
            conn = sqlite3.connect(self.cache_db_path)
            cursor = conn.cursor()

            cursor.execute(
                "SELECT query_hash, query_text FROM query_cache WHERE db_name = ?",
                (db_name,)
            )
            cached_queries = cursor.fetchall()
            conn.close()

            if not cached_queries:
                return None

            try:
                # å°è¯•ä½¿ç”¨TF-IDFè®¡ç®—ç›¸ä¼¼åº¦
                from sklearn.feature_extraction.text import TfidfVectorizer
                from sklearn.metrics.pairwise import cosine_similarity

                # å‡†å¤‡æ–‡æœ¬åˆ—è¡¨
                all_texts = [query] + [q[1] for q in cached_queries]
                query_hashes = [None] + [q[0] for q in cached_queries]

                vectorizer = TfidfVectorizer()
                tfidf_matrix = vectorizer.fit_transform(all_texts)
                similarities = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])

                # æ‰¾å‡ºæœ€ç›¸ä¼¼çš„æŸ¥è¯¢
                if similarities.size > 0:
                    max_idx = similarities[0].argmax()
                    max_similarity = similarities[0][max_idx]

                    if max_similarity >= self.similarity_threshold:
                        st.info(f"ä½¿ç”¨æ–‡æœ¬ç›¸ä¼¼åº¦æ‰¾åˆ°ç›¸ä¼¼é—®é¢˜ï¼Œç›¸ä¼¼åº¦: {max_similarity:.2f}")
                        return query_hashes[max_idx + 1]
            except Exception as e:
                st.warning(f"æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {str(e)}")
                # å¦‚æœTF-IDFå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å…³é”®è¯åŒ¹é…
                return self._keyword_matching_fallback(query, cached_queries)

            return None
        except Exception as e:
            st.warning(f"å¤‡é€‰ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {str(e)}")
            return None

    def _keyword_matching_fallback(self, query, cached_queries):
        """æœ€åçš„å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨ç®€å•çš„å…³é”®è¯åŒ¹é…"""
        import re

        # ç®€å•çš„åˆ†è¯
        def extract_keywords(text):
            # ç®€å•åˆ†è¯ï¼ˆè‹±æ–‡æŒ‰ç©ºæ ¼ï¼Œä¸­æ–‡æŒ‰å­—ç¬¦ï¼‰
            words = re.findall(r'\w+|[\u4e00-\u9fff]', text.lower())
            # ç®€å•çš„åœç”¨è¯è¿‡æ»¤
            stopwords = {'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'the', 'a', 'an', 'of', 'to', 'in',
                         'for', 'and', 'is', 'on', 'that', 'by'}
            return [w for w in words if w not in stopwords and len(w) > 1]

        query_keywords = set(extract_keywords(query))
        if not query_keywords:
            return None

        # è®¡ç®—å…³é”®è¯åŒ¹é…åº¦
        max_similarity = 0
        most_similar_hash = None

        for query_hash, query_text in cached_queries:
            cached_keywords = set(extract_keywords(query_text))

            # è®¡ç®—å…³é”®è¯é‡å åº¦
            if not cached_keywords:
                continue

            common_keywords = query_keywords & cached_keywords
            if not common_keywords:
                continue

            # è®¡ç®—Jaccardç›¸ä¼¼åº¦
            similarity = len(common_keywords) / len(query_keywords | cached_keywords)

            if similarity > max_similarity:
                max_similarity = similarity
                most_similar_hash = query_hash

        # å¦‚æœç›¸ä¼¼åº¦è¶…è¿‡é˜ˆå€¼ï¼Œè¿”å›æœ€ç›¸ä¼¼æŸ¥è¯¢çš„å“ˆå¸Œå€¼
        if max_similarity >= self.similarity_threshold:
            st.info(f"ä½¿ç”¨å…³é”®è¯åŒ¹é…æ‰¾åˆ°ç›¸ä¼¼é—®é¢˜ï¼Œç›¸ä¼¼åº¦: {max_similarity:.2f}")
            return most_similar_hash

        return None

    def get_from_cache(self, query, db_name):
        """ä»ç¼“å­˜ä¸­è·å–æŸ¥è¯¢ç»“æœï¼Œæ”¯æŒè¯­ä¹‰ç›¸ä¼¼åŒ¹é…"""
        # é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…
        query_hash = self._generate_hash(query, db_name)

        conn = sqlite3.connect(self.cache_db_path)
        cursor = conn.cursor()

        cursor.execute(
            "SELECT sql, query_text FROM query_cache WHERE query_hash = ?",
            (query_hash,)
        )
        result = cursor.fetchone()

        # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œå°è¯•æŸ¥æ‰¾è¯­ä¹‰ç›¸ä¼¼çš„æŸ¥è¯¢
        if not result:
            similar_hash = self._find_similar_query(query, db_name)
            if similar_hash:
                cursor.execute(
                    "SELECT sql, query_text FROM query_cache WHERE query_hash = ?",
                    (similar_hash,)
                )
                result = cursor.fetchone()
                query_hash = similar_hash  # æ›´æ–°å“ˆå¸Œå€¼ä»¥ä¾¿æ›´æ–°è®¿é—®ç»Ÿè®¡

        if result:
            # æ›´æ–°è®¿é—®æ—¶é—´å’Œè®¡æ•°
            cursor.execute(
                "UPDATE query_cache SET accessed_at = ?, access_count = access_count + 1 WHERE query_hash = ?",
                (datetime.now(), query_hash)
            )
            conn.commit()

            sql, cached_query = result

            # æ˜¾ç¤ºç¼“å­˜å‘½ä¸­ä¿¡æ¯
            if cached_query == query:
                st.success("âœ… ä»ç¼“å­˜ä¸­è·å–åˆ°å®Œå…¨åŒ¹é…çš„SQL")
            else:
                st.success(f"âœ… ä»ç¼“å­˜ä¸­è·å–åˆ°ç›¸ä¼¼é—®é¢˜çš„SQL: \"{cached_query}\"")

            st.code(f"ç¼“å­˜çš„SQLæŸ¥è¯¢:\n{sql}", language="sql")

            conn.close()
            return sql  # åªè¿”å›SQLè¯­å¥

        conn.close()
        return None

    def save_to_cache(self, query, db_name, sql):
        """ä¿å­˜SQLæŸ¥è¯¢åˆ°ç¼“å­˜ï¼ŒåŒ…æ‹¬åµŒå…¥å‘é‡"""
        query_hash = self._generate_hash(query, db_name)

        # è·å–æŸ¥è¯¢çš„åµŒå…¥å‘é‡
        query_embedding = None
        if self.embedding_available:
            query_embedding = self._get_embedding(query)
        query_embedding_json = json.dumps(query_embedding) if query_embedding else None

        conn = sqlite3.connect(self.cache_db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            INSERT OR REPLACE INTO query_cache 
            (query_hash, query_text, query_embedding, db_name, sql, created_at, accessed_at, access_count) 
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """,
            (
                query_hash,
                query,
                query_embedding_json,
                db_name,
                sql,
                datetime.now(),
                datetime.now(),
                1
            )
        )

        conn.commit()
        conn.close()

        # å¼ºåˆ¶æ‰§è¡Œç¼“å­˜å¤§å°é™åˆ¶
        self.enforce_cache_size_limit()

    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        conn = sqlite3.connect(self.cache_db_path)
        cursor = conn.cursor()
        cursor.execute("DELETE FROM query_cache")
        conn.commit()
        conn.close()
        return "ç¼“å­˜å·²æ¸…ç©º"

    def get_cache_stats(self):
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        conn = sqlite3.connect(self.cache_db_path)
        cursor = conn.cursor()

        cursor.execute("SELECT COUNT(*) FROM query_cache")
        total_entries = cursor.fetchone()[0]

        cursor.execute("SELECT SUM(access_count) FROM query_cache")
        total_hits = cursor.fetchone()[0] or 0

        cursor.execute("SELECT query_text, access_count FROM query_cache ORDER BY access_count DESC LIMIT 5")
        top_queries = cursor.fetchall()

        conn.close()

        return {
            "total_entries": total_entries,
            "total_hits": total_hits,
            "top_queries": top_queries
        }

    def is_cache_expired(self, created_at, expiry_days=7):
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ"""
        # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºdatetimeå¯¹è±¡
        if isinstance(created_at, str):
            created_at = datetime.fromisoformat(created_at)

        # è®¡ç®—è¿‡æœŸæ—¶é—´
        expiry_date = created_at + timedelta(days=expiry_days)
        return datetime.now() > expiry_date

    def enforce_cache_size_limit(self, max_entries=1000):
        """é™åˆ¶ç¼“å­˜æ¡ç›®æ•°é‡ï¼Œåˆ é™¤æœ€ä¸å¸¸ç”¨çš„æ¡ç›®"""
        conn = sqlite3.connect(self.cache_db_path)
        cursor = conn.cursor()

        # è·å–å½“å‰ç¼“å­˜æ¡ç›®æ•°
        cursor.execute("SELECT COUNT(*) FROM query_cache")
        count = cursor.fetchone()[0]

        # å¦‚æœè¶…è¿‡é™åˆ¶ï¼Œåˆ é™¤æœ€ä¸å¸¸ç”¨çš„æ¡ç›®
        if count > max_entries:
            entries_to_delete = count - max_entries
            cursor.execute(
                "DELETE FROM query_cache WHERE query_hash IN (SELECT query_hash FROM query_cache ORDER BY access_count, accessed_at LIMIT ?)",
                (entries_to_delete,)
            )
            conn.commit()

        conn.close()




class NLDatabaseQuery:
    def __init__(self, db_config: Dict, api_key: str, cache_system: SemanticQueryCache = None):
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥å’ŒOpenAIå®¢æˆ·ç«¯
        self.db_config = db_config
        # ä¿®æ”¹ä¸ºOpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–
        self.client = OpenAI(
            api_key=api_key,
            base_url="https://open.bigmodel.cn/api/paas/v4/"
        )
        self.conn = None
        self.cursor = None
        self.connect_db()

        # æ·»åŠ ç¼“å­˜ç³»ç»Ÿ
        self.cache = cache_system if cache_system else SemanticQueryCache()
        # è®¾ç½®APIå®¢æˆ·ç«¯åˆ°ç¼“å­˜ç³»ç»Ÿ
        self.cache.set_api_client(self.client)

    def connect_db(self):
        # å»ºç«‹æ•°æ®åº“è¿æ¥
        try:
            self.conn = mysql.connector.connect(**self.db_config)
            self.cursor = self.conn.cursor(dictionary=True)
        except Exception as e:
            st.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
            raise

    def extract_tables_from_sql(self, sql: str) -> List[str]:
        """ä»SQLè¯­å¥ä¸­æå–è¡¨å"""
        import re
        # åŒ¹é…FROMå’ŒJOINåé¢çš„è¡¨å
        from_pattern = r'(?:FROM|JOIN)\s+`?(\w+)`?'
        tables = re.findall(from_pattern, sql, re.IGNORECASE)
        # å»é‡
        return list(set(tables))

    def get_schema_info(self, tables=None):
        """è·å–æ•°æ®åº“schemaä¿¡æ¯ï¼Œè¿”å›å»ºè¡¨è¯­å¥ï¼Œæ”¯æŒè¡¨è¿‡æ»¤"""
        schema_info = []

        if tables:
            # åªè·å–æŒ‡å®šè¡¨çš„å»ºè¡¨è¯­å¥
            for table_name in tables:
                try:
                    # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                    self.cursor.execute("""
                        SELECT 1 
                        FROM information_schema.TABLES 
                        WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s
                    """, (self.db_config['database'], table_name))

                    result = self.cursor.fetchone()
                    # ç¡®ä¿å®Œå…¨æ¶ˆè´¹ç»“æœé›†
                    self.cursor.fetchall()
                    
                    if result:
                        # è·å–è¡¨çš„å»ºè¡¨è¯­å¥
                        self.cursor.execute(f"SHOW CREATE TABLE `{table_name}`")
                        create_table = self.cursor.fetchone()
                        # ç¡®ä¿å®Œå…¨æ¶ˆè´¹ç»“æœé›†
                        self.cursor.fetchall()
                        
                        if create_table and 'Create Table' in create_table:
                            schema_info.append(create_table['Create Table'])
                except Exception as e:
                    st.warning(f"è·å–è¡¨ {table_name} çš„schemaä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")
                    # å°è¯•é‡ç½®è¿æ¥çŠ¶æ€
                    try:
                        self.cursor.fetchall()
                    except:
                        pass
        else:
            # åŸå§‹é€»è¾‘ - è·å–æ‰€æœ‰è¡¨
            self.cursor.execute("""
                SELECT TABLE_NAME 
                FROM information_schema.TABLES 
                WHERE TABLE_SCHEMA = %s
            """, (self.db_config['database'],))

            tables = self.cursor.fetchall()
            # ç¡®ä¿å®Œå…¨æ¶ˆè´¹ç»“æœé›†
            self.cursor.fetchall()
            
            for table in tables:
                table_name = table['TABLE_NAME']

                # è·å–è¡¨çš„å»ºè¡¨è¯­å¥
                self.cursor.execute(f"SHOW CREATE TABLE `{table_name}`")
                create_table = self.cursor.fetchone()
                # ç¡®ä¿å®Œå…¨æ¶ˆè´¹ç»“æœé›†
                self.cursor.fetchall()
                
                if create_table and 'Create Table' in create_table:
                    schema_info.append(create_table['Create Table'])

        return "\n\n".join(schema_info)

    def get_specific_schema_info(self, tables: List[str]) -> str:
        """è·å–æŒ‡å®šè¡¨çš„schemaä¿¡æ¯ï¼Œè¿”å›å»ºè¡¨è¯­å¥"""
        if not tables:
            return "æœªæ‰¾åˆ°ç›¸å…³è¡¨çš„schemaä¿¡æ¯"
    
        schema_info = []
        for table_name in tables:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            self.cursor.execute("""
                SELECT 1 
                FROM information_schema.TABLES 
                WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s
            """, (self.db_config['database'], table_name))
            
            result = self.cursor.fetchone()
            # ç¡®ä¿å®Œå…¨æ¶ˆè´¹ç»“æœé›†
            self.cursor.fetchall()
            
            if not result:
                continue
            
            # è·å–è¡¨çš„å»ºè¡¨è¯­å¥
            try:
                self.cursor.execute(f"SHOW CREATE TABLE `{table_name}`")
                create_table = self.cursor.fetchone()
                # ç¡®ä¿å®Œå…¨æ¶ˆè´¹ç»“æœé›†
                self.cursor.fetchall()
                
                if create_table and 'Create Table' in create_table:
                    schema_info.append(create_table['Create Table'])
            except Exception as e:
                schema_info.append(f"è·å–è¡¨ {table_name} çš„å»ºè¡¨è¯­å¥æ—¶å‡ºé”™: {str(e)}")
                # å°è¯•é‡ç½®è¿æ¥çŠ¶æ€
                try:
                    self.cursor.fetchall()
                except:
                    pass
        
        return "\n\n".join(schema_info) if schema_info else "æœªæ‰¾åˆ°ç›¸å…³è¡¨çš„schemaä¿¡æ¯"

    def generate_sql_prompt(self, query: str, schema_info: str) -> List[Dict]:
        """ç”Ÿæˆæç¤ºä¿¡æ¯ï¼Œå¼•å¯¼æ¨¡å‹ç”ŸæˆSQLæŸ¥è¯¢ï¼Œå¼ºè°ƒæ¨¡å—çº¦æŸ"""
        # æ£€æµ‹æ˜¯å¦ä½¿ç”¨äº†æ¨¡å—è¿‡æ»¤
        is_filtered = len(schema_info.splitlines()) < 10000  # ç²—ç•¥ä¼°è®¡å…¨åº“è¡¨ç»“æ„è¡Œæ•°

        module_hint = ""
        if is_filtered:
            module_hint = """
            æ³¨æ„ï¼šå½“å‰åªæä¾›äº†ä¸ç”¨æˆ·æŸ¥è¯¢æ„å›¾ç›¸å…³çš„è¡¨ç»“æ„ä¿¡æ¯ï¼Œè¯·åªä½¿ç”¨æä¾›çš„è¡¨ç»“æ„ç”ŸæˆSQLï¼Œä¸è¦å°è¯•ä½¿ç”¨ä¸åœ¨schemaä¸­çš„è¡¨ã€‚
            """

        return [
            {"role": "system", "content": f"""ä½ æ˜¯ä¸€ä¸ªSQLä¸“å®¶ï¼Œè´Ÿè´£å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºSQLæŸ¥è¯¢è¯­å¥ã€‚
                è¯·æ³¨æ„ï¼š
                1. ç›´æ¥è¿”å›SQLè¯­å¥ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–ä¿¡æ¯ã€‚
                2. ç°åœ¨ä½¿ç”¨çš„æ˜¯MySQL 5.7.37æ•°æ®åº“ï¼Œç¡®ä¿SQLè¯­å¥è¯­æ³•æ­£ç¡®
                3. ä½¿ç”¨æä¾›çš„schemaä¿¡æ¯æ„å»ºæŸ¥è¯¢
                4. æ³¨æ„ä½¿ç”¨é€‚å½“çš„è¡¨è¿æ¥å’Œæ¡ä»¶
                5. æŸ¥è¯¢çš„è¡¨å¤´éƒ½éœ€è¦æœ‰ä¸­æ–‡æ³¨é‡Šï¼Œä¸è¦ä½¿ç”¨è¡¨åˆ«å
                6. ç¡®ä¿æŸ¥è¯¢å®‰å…¨ï¼Œé¿å…SQLæ³¨å…¥é£é™©
                7. æ£€æŸ¥è¡¨åå’Œå­—æ®µåæ˜¯å¦æ­£ç¡®ï¼Œç¡®ä¿å®ƒä»¬å­˜åœ¨äºschemaä¸­
                8. è€ƒè™‘å¯èƒ½çš„æ•°æ®ç±»å‹è½¬æ¢é—®é¢˜
                9. ç¡®ä¿WHEREæ¡ä»¶åˆç†
                {module_hint}"""},
            {"role": "user", "content": f"""
                æ•°æ®åº“Schemaä¿¡æ¯å¦‚ä¸‹ï¼š
                {schema_info}

                è¯·å°†ä»¥ä¸‹é—®é¢˜è½¬æ¢ä¸ºSQLæŸ¥è¯¢è¯­å¥ï¼š
                {query}
                """}
        ]

    def generate_answer_prompt(self, result: str, query: str, sql: str, schema_info: str) -> List[Dict]:
        return [
            {"role": "system", "content": """ä½ æ˜¯ä¸€ä¸ªSQLæŸ¥è¯¢è§£è¯»ä¸“å®¶ï¼Œè´Ÿè´£å°†SQLæŸ¥è¯¢ç»“æœè½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€åˆ†æå’Œå¯è§†åŒ–æ•°æ®ã€‚ä½ æ“…é•¿æ•°æ®åˆ†æå¹¶èƒ½å¤Ÿæ¨èæœ€åˆé€‚çš„å¯è§†åŒ–æ–¹å¼ã€‚"""},
            {"role": "user", "content": f"""è¯·å¸®æˆ‘åˆ†æä»¥ä¸‹æŸ¥è¯¢ç»“æœï¼Œæä¾›ä¸“ä¸šçš„æ•°æ®æ´å¯Ÿï¼š
                æŸ¥è¯¢çš„é—®é¢˜ï¼š
                {query}
                æŸ¥è¯¢ç”¨åˆ°çš„sqlï¼š 
                {sql}
                æ•°æ®åº“Schemaä¿¡æ¯å¦‚ä¸‹ï¼š 
                {schema_info}
                æŸ¥è¯¢ç»“æœï¼š
                {result}

                è¯·æä¾›ã€markdownæ ¼å¼ã€‘ï¼š
                1. æ•°æ®çš„ä¸“ä¸šåˆ†æå’Œæ´å¯Ÿï¼ˆæ— éœ€å±•ç¤ºåŸå§‹æ•°æ®è¡¨æ ¼ï¼Œå› ä¸ºæ•°æ®å·²ç›´æ¥æ˜¾ç¤ºåœ¨ç•Œé¢ä¸Šï¼‰
                2. å…³é”®è¶‹åŠ¿ã€å¼‚å¸¸å€¼æˆ–é‡è¦å‘ç°çš„è§£é‡Š

                å¦å¤–ï¼Œè¯·åˆ†ææ•°æ®ç‰¹ç‚¹ï¼Œé€‰æ‹©æœ€åˆé€‚çš„å›¾è¡¨ç±»å‹è¿›è¡Œå¯è§†åŒ–ï¼Œå¹¶æä¾›ä»¥ä¸‹JSONæ ¼å¼çš„å¯è§†åŒ–é…ç½®ï¼šã€æ³¨æ„ï¼ï¼ï¼š1.jsonä¸­ä¸å¯å«æœ‰ä»»ä½•æ³¨é‡Šï¼Œç‰¹åˆ«æ˜¯valueé‡Œé¢ä¸èƒ½å«æœ‰ä»»ä½•æ³¨é‡Š;2.è‹¥æœ‰å¤šä¸ªå›¾è¡¨ï¼Œä»¥jsonæ•°ç»„å½¢å¼ä¸€å¹¶è¿”å›ã€‘

                ```json
                {{
                  "charts": [
                    {{
                      "type": "å›¾è¡¨ç±»å‹1",  
                      "title": "å›¾è¡¨æ ‡é¢˜1",
                      "description": "å›¾è¡¨æè¿°1",
                      "data": {{
                        // æ ¹æ®å›¾è¡¨ç±»å‹æä¾›ç›¸åº”çš„æ•°æ®é…ç½®
                      }}
                    }},
                    {{
                      "type": "å›¾è¡¨ç±»å‹2",  
                      "title": "å›¾è¡¨æ ‡é¢˜2",
                      "description": "å›¾è¡¨æè¿°2",
                      "data": {{
                        // æ ¹æ®å›¾è¡¨ç±»å‹æä¾›ç›¸åº”çš„æ•°æ®é…ç½®
                      }}
                    }}
                  ]
                }}
                ```

                æ”¯æŒçš„å›¾è¡¨ç±»å‹å’Œé…ç½®è¯´æ˜ï¼š

                1. é¥¼å›¾ (pie)ï¼šé€‚åˆå±•ç¤ºå æ¯”å…³ç³»
                ```json
                {{
                  "type": "pie",
                  "data": {{
                    "labels": ["ç±»åˆ«1", "ç±»åˆ«2", "ç±»åˆ«3"],  // åˆ†ç±»æ ‡ç­¾
                    "values": [30, 40, 50],  // å¯¹åº”çš„æ•°å€¼
                    "hole": 0.4,  // å¯é€‰ï¼Œè®¾ç½®ä¸­å¿ƒå­”å¤§å°(0-1)ï¼Œç”¨äºåˆ›å»ºç¯å½¢å›¾
                    "colors": ["#ff0000", "#00ff00", "#0000ff"]  // å¯é€‰ï¼Œè‡ªå®šä¹‰é¢œè‰²
                  }}
                }}
                ```

                2. æŸ±çŠ¶å›¾ (bar)ï¼šé€‚åˆåˆ†ç±»æ•°æ®æ¯”è¾ƒ
                ```json
                {{
                  "type": "bar",
                  "data": {{
                    "labels": ["ç±»åˆ«1", "ç±»åˆ«2", "ç±»åˆ«3"],  // Xè½´æ ‡ç­¾
                    "values": [30, 40, 50],  // Yè½´æ•°å€¼
                    "orientation": "v",  // å¯é€‰ï¼Œ'v'å‚ç›´æŸ±çŠ¶å›¾(é»˜è®¤)ï¼Œ'h'æ°´å¹³æŸ±çŠ¶å›¾
                    "is_grouped": false,  // å¯é€‰ï¼Œæ˜¯å¦ä¸ºåˆ†ç»„æŸ±çŠ¶å›¾
                    "is_stacked": false,  // å¯é€‰ï¼Œæ˜¯å¦ä¸ºå †å æŸ±çŠ¶å›¾
                    "show_values": true,  // å¯é€‰ï¼Œæ˜¯å¦æ˜¾ç¤ºæ•°å€¼
                    "colors": ["#ff0000", "#00ff00", "#0000ff"]  // å¯é€‰ï¼Œè‡ªå®šä¹‰é¢œè‰²
                  }}
                }}
                ```

                3. æŠ˜çº¿å›¾ (line)ï¼šé€‚åˆæ—¶é—´åºåˆ—å’Œè¶‹åŠ¿åˆ†æ
                ```json
                {{
                  "type": "line",
                  "data": {{
                    "labels": ["2023-01", "2023-02", "2023-03"],  // Xè½´æ ‡ç­¾(é€šå¸¸æ˜¯æ—¶é—´)
                    "values": [30, 40, 50],  // Yè½´æ•°å€¼
                    "show_markers": true,  // å¯é€‰ï¼Œæ˜¯å¦æ˜¾ç¤ºæ•°æ®ç‚¹
                    "line_shape": "linear",  // å¯é€‰ï¼Œçº¿å‹: linear, spline
                    "x_axis_title": "æ—¶é—´",  // å¯é€‰ï¼ŒXè½´æ ‡é¢˜
                    "y_axis_title": "é”€å”®é¢",  // å¯é€‰ï¼ŒYè½´æ ‡é¢˜
                    // å¤šç³»åˆ—æ•°æ®(å¯é€‰)
                    "series": [
                      {{
                        "name": "ç³»åˆ—1",
                        "x": ["2023-01", "2023-02", "2023-03"],
                        "y": [30, 40, 50],
                        "line_width": 2
                      }},
                      {{
                        "name": "ç³»åˆ—2",
                        "x": ["2023-01", "2023-02", "2023-03"],
                        "y": [20, 30, 40],
                        "line_width": 2
                      }}
                    ]
                  }}
                }}
                ```

                4. æ•£ç‚¹å›¾ (scatter)ï¼šé€‚åˆæ¢ç´¢ä¸¤ä¸ªå˜é‡çš„å…³ç³»
                ```json
                {{
                  "type": "scatter",
                  "data": {{
                    "x": [10, 20, 30, 40],  // Xè½´æ•°å€¼
                    "y": [5, 15, 25, 35],   // Yè½´æ•°å€¼
                    "sizes": [10, 20, 30, 40],  // å¯é€‰ï¼Œæ°”æ³¡å¤§å°
                    "color_values": [1, 2, 3, 4],  // å¯é€‰ï¼Œé¢œè‰²ç»´åº¦
                    "hover_names": ["ç‚¹1", "ç‚¹2", "ç‚¹3", "ç‚¹4"],  // å¯é€‰ï¼Œæ‚¬åœæ˜¾ç¤ºçš„æ ‡ç­¾
                    "opacity": 0.7  // å¯é€‰ï¼Œé€æ˜åº¦
                  }}
                }}
                ```

                5. é¢ç§¯å›¾ (area)ï¼šå±•ç¤ºè¶‹åŠ¿å’Œç´¯è®¡å…³ç³»
                ```json
                {{
                  "type": "area",
                  "data": {{
                    "labels": ["2023-01", "2023-02", "2023-03"],  // Xè½´æ ‡ç­¾
                    "values": [30, 40, 50],  // Yè½´æ•°å€¼
                    "is_stacked": true,  // å¯é€‰ï¼Œæ˜¯å¦å †å 
                    "colors": ["#ff0000", "#00ff00", "#0000ff"]  // å¯é€‰ï¼Œè‡ªå®šä¹‰é¢œè‰²
                  }}
                }}
                ```

                6. çƒ­åŠ›å›¾ (heatmap)ï¼šå±•ç¤ºäºŒç»´æ•°æ®çš„å¼ºåº¦å˜åŒ–
                ```json
                {{
                  "type": "heatmap",
                  "data": {{
                    "z_values": [[1, 2, 3], [4, 5, 6], [7, 8, 9]],  // çƒ­åŠ›å€¼(äºŒç»´æ•°ç»„)
                    "x_labels": ["A", "B", "C"],  // Xè½´æ ‡ç­¾
                    "y_labels": ["X", "Y", "Z"],  // Yè½´æ ‡ç­¾
                    "color_scale": "Viridis",  // å¯é€‰ï¼Œé¢œè‰²æ¯”ä¾‹å°º
                    "show_values": true  // å¯é€‰ï¼Œæ˜¯å¦æ˜¾ç¤ºæ•°å€¼
                  }}
                }}
                ```

                7. é›·è¾¾å›¾ (radar)ï¼šå¤šç»´åº¦æ•°æ®æ¯”è¾ƒ
                ```json
                {{
                  "type": "radar",
                  "data": {{
                    "labels": ["æŒ‡æ ‡1", "æŒ‡æ ‡2", "æŒ‡æ ‡3", "æŒ‡æ ‡4", "æŒ‡æ ‡5"],  // ç»´åº¦æ ‡ç­¾
                    "values": [80, 65, 90, 75, 85],  // å•ä¸ªç³»åˆ—çš„å€¼
                    "max_value": 100,  // å¯é€‰ï¼Œæœ€å¤§å€¼
                    // å¤šç³»åˆ—æ•°æ®(å¯é€‰)
                    "series": [
                      {{
                        "name": "äº§å“A",
                        "values": [80, 65, 90, 75, 85]
                      }},
                      {{
                        "name": "äº§å“B",
                        "values": [70, 75, 80, 65, 95]
                      }}
                    ]
                  }}
                }}
                ```

                8. æ¼æ–—å›¾ (funnel)ï¼šå±•ç¤ºæµç¨‹è½¬åŒ–ç‡
                ```json
                {{
                  "type": "funnel",
                  "data": {{
                    "labels": ["è®¿é—®", "æ³¨å†Œ", "ä¸‹å•", "æ”¯ä»˜", "å¤è´­"],  // é˜¶æ®µæ ‡ç­¾
                    "values": [1000, 800, 600, 400, 200],  // å„é˜¶æ®µæ•°å€¼
                    "text_info": "value+percent"  // å¯é€‰ï¼Œæ˜¾ç¤ºçš„æ–‡æœ¬ä¿¡æ¯
                  }}
                }}
                ```

                è¯·æ ¹æ®æ•°æ®ç‰¹ç‚¹é€‰æ‹©æœ€åˆé€‚çš„å›¾è¡¨ç±»å‹ï¼Œæœ€å¤šæä¾›2ä¸ªå›¾è¡¨é…ç½®ã€‚ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥è¢«è§£æã€‚å¦‚æœæ•°æ®ä¸é€‚åˆå¯è§†åŒ–ï¼Œå¯ä»¥ä¸æä¾›å›¾è¡¨é…ç½®ã€‚
                """}
        ]



    # æ¸…ç†å¤§æ¨¡å‹è¿”å›çš„SQLæ–‡æœ¬ï¼Œå»é™¤ä»£ç å—æ ‡è®°å’Œå…¶ä»–æ ¼å¼
    def clean_sql_response(self, response_text: str):
        patterns = [
            r'```sql\s*(.*?)\s*```',  # SQLä»£ç å—
            r'```\s*(.*?)\s*```',  # æ™®é€šä»£ç å—
            r'`(.*?)`'  # å†…è”ä»£ç å—
        ]

        cleaned_text = response_text
        for pattern in patterns:
            import re
            matches = re.findall(pattern, cleaned_text, re.DOTALL)
            if matches:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªåŒ¹é…åˆ°çš„SQLè¯­å¥
                cleaned_text = matches[0]
                break

        # å»é™¤å¤šä½™çš„ç©ºè¡Œå’Œé¦–å°¾ç©ºç™½
        cleaned_text = '\n'.join(line.strip() for line in cleaned_text.splitlines() if line.strip())

        return cleaned_text

    def extract_chart_config(self, response_text: str):
        """ä»å“åº”æ–‡æœ¬ä¸­æå–å›¾è¡¨é…ç½®JSON"""
        import re
        with st.expander("æ¸…æ´—å‰ï¼š", expanded=False):
            st.write(response_text)
        response_text = self.clean_json_comments(response_text)
        with st.expander("æ¸…æ´—åï¼š", expanded=False):
            st.write(response_text)
        json_pattern = r'```json\s*(.*?)\s*```'
        matches = re.findall(json_pattern, response_text, re.DOTALL)

        if matches:
            try:
                return json.loads(matches[0])
            except json.JSONDecodeError:
                st.warning("å›¾è¡¨é…ç½®JSONæ ¼å¼é”™è¯¯ï¼Œæ— æ³•è§£æ")

        return None

    def is_valid_query_result(self, result):
        """åˆ¤æ–­æŸ¥è¯¢ç»“æœæ˜¯å¦æœ‰æ•ˆä¸”å€¼å¾—ç¼“å­˜"""
        # æ£€æŸ¥ç»“æœæ˜¯å¦ä¸ºç©º
        if not result:
            return False

        # æ£€æŸ¥ç»“æœæ˜¯å¦ä¸ºåˆ—è¡¨ä¸”åŒ…å«è‡³å°‘ä¸€æ¡è®°å½•
        if not isinstance(result, list) or len(result) == 0:
            return False

        # æ£€æŸ¥ç¬¬ä¸€æ¡è®°å½•æ˜¯å¦ä¸ºå­—å…¸ä¸”åŒ…å«æ•°æ®
        if not isinstance(result[0], dict) or len(result[0]) == 0:
            return False

        # ç»“æœæœ‰æ•ˆ
        return True

    def execute_query(self, sql: str) -> List[Dict]:
        """æ‰§è¡ŒSQLæŸ¥è¯¢ï¼Œå¢åŠ é”™è¯¯å¤„ç†"""
        try:
            self.cursor.execute(sql)
            result = self.cursor.fetchall()
            # ç¡®ä¿å®Œå…¨æ¶ˆè´¹ç»“æœé›†ï¼Œé¿å…Commands out of syncé”™è¯¯
            if not result:
                # å³ä½¿æ²¡æœ‰ç»“æœä¹Ÿè°ƒç”¨ä¸€æ¬¡fetchallç¡®ä¿ç»“æœé›†è¢«æ¶ˆè´¹
                self.cursor.fetchall()
                
            if result:
                st.success(f"æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› {len(result)} æ¡è®°å½•")
            else:
                st.warning("æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼Œä½†æ²¡æœ‰è¿”å›æ•°æ®")
            return result
        except Exception as e:
            st.error(f"æŸ¥è¯¢æ‰§è¡Œé”™è¯¯: {str(e)}")
            # å‘ç”Ÿé”™è¯¯æ—¶ï¼Œå°è¯•é‡ç½®è¿æ¥çŠ¶æ€
            try:
                # å°è¯•æ¶ˆè´¹ä»»ä½•æœªå¤„ç†çš„ç»“æœé›†
                self.cursor.fetchall()
            except:
                # å¦‚æœé‡ç½®å¤±è´¥ï¼Œé‡æ–°å»ºç«‹è¿æ¥
                try:
                    self.connect_db()
                except Exception as conn_error:
                    st.error(f"é‡æ–°è¿æ¥æ•°æ®åº“å¤±è´¥: {str(conn_error)}")
            return []

    def natural_language_query(self, query: str, module: str = None, max_retries: int = 2) -> tuple:
        """æ‰§è¡Œè‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œæ”¯æŒç¼“å­˜ï¼Œåªç¼“å­˜æˆåŠŸçš„æŸ¥è¯¢ï¼Œæ”¯æŒè‡ªåŠ¨é‡è¯•"""
        # é¦–å…ˆå°è¯•ä»ç¼“å­˜ä¸­è·å–SQLï¼ˆæ”¯æŒè¯­ä¹‰ç›¸ä¼¼æ€§åŒ¹é…ï¼‰
        cached_sql = self.cache.get_from_cache(
            query, self.db_config['database']
        )

        error_info = None  # ç”¨äºå­˜å‚¨é”™è¯¯ä¿¡æ¯
        failed_sql = None  # ç”¨äºå­˜å‚¨å¤±è´¥çš„SQL

        if cached_sql is not None:
            # ä½¿ç”¨ç¼“å­˜çš„SQLæ‰§è¡ŒæŸ¥è¯¢
            sql = cached_sql
            # æ‰§è¡ŒSQLæŸ¥è¯¢
            try:
                result = self.execute_query(sql)

                # å¦‚æœç¼“å­˜çš„SQLæ‰§è¡Œå¤±è´¥æˆ–è¿”å›ä¸ºç©ºï¼Œåˆ™å°è¯•é‡æ–°ç”ŸæˆSQL
                if not self.is_valid_query_result(result) and max_retries > 0:
                    st.warning(f"ç¼“å­˜çš„SQLæ‰§è¡Œå¤±è´¥æˆ–è¿”å›ä¸ºç©ºï¼Œå°†å°è¯•é‡æ–°ç”ŸæˆSQLï¼ˆå‰©ä½™é‡è¯•æ¬¡æ•°ï¼š{max_retries}ï¼‰")
                    failed_sql = sql
                    return self._retry_query_generation(query, max_retries, failed_sql, error_info, module)
            except Exception as e:
                error_info = str(e)
                st.error(f"ç¼“å­˜çš„SQLæ‰§è¡Œé”™è¯¯: {error_info}")
                if max_retries > 0:
                    st.warning(f"å°†å°è¯•é‡æ–°ç”ŸæˆSQLï¼ˆå‰©ä½™é‡è¯•æ¬¡æ•°ï¼š{max_retries}ï¼‰")
                    failed_sql = sql
                    return self._retry_query_generation(query, max_retries - 1, failed_sql, error_info, module)
                result = []
        else:
            # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰ï¼Œåˆ™ç”Ÿæˆæ–°çš„SQL

            # ã€æ–°å¢ä»£ç ã€‘æ ¹æ®æ¨¡å—è¿‡æ»¤è¡¨
            if module:
                relevant_tables = self.get_tables_by_module(module)
                if relevant_tables:
                    st.info(f"ğŸ” æ ¹æ®ä¸šåŠ¡æ¨¡å— '{module}' è¿‡æ»¤è¡¨ï¼Œç¼©å°æŸ¥è¯¢èŒƒå›´")
                    schema_info = self.get_schema_info(relevant_tables)
                else:
                    st.warning(f"âš ï¸ æœªæ‰¾åˆ°ä¸šåŠ¡æ¨¡å— '{module}' çš„ç›¸å…³è¡¨ï¼Œå°†ä½¿ç”¨æ‰€æœ‰è¡¨")
                    schema_info = self.get_schema_info()
            else:
                st.warning("âš ï¸ æœªæ‰¾åˆ°ä¸šåŠ¡æ¨¡å—ï¼Œå°†ä½¿ç”¨æ‰€æœ‰è¡¨")
                schema_info = self.get_schema_info()

            # ç”Ÿæˆå¹¶å‘é€promptåˆ°æ¨¡å‹
            messages = self.generate_sql_prompt(query, schema_info)
            with st.expander("promptä¿¡æ¯ï¼š", expanded=False):
                st.write(messages)
            response = self.client.chat.completions.create(
                model="glm-4-plus",
                messages=messages
            )
            # è·å–ç”Ÿæˆçš„SQL
            sql = response.choices[0].message.content.strip()
            sql = self.clean_sql_response(sql)
            st.code(f"ç”Ÿæˆçš„SQLæŸ¥è¯¢:\n{sql}", language="sql")
            # æ‰§è¡ŒSQLæŸ¥è¯¢
            try:
                result = self.execute_query(sql)

                # å¦‚æœSQLæ‰§è¡Œå¤±è´¥æˆ–è¿”å›ä¸ºç©ºï¼Œåˆ™å°è¯•é‡æ–°ç”ŸæˆSQL
                if not self.is_valid_query_result(result) and max_retries > 0:
                    st.warning(f"ç”Ÿæˆçš„SQLæ‰§è¡Œå¤±è´¥æˆ–è¿”å›ä¸ºç©ºï¼Œå°†å°è¯•é‡æ–°ç”Ÿæˆï¼ˆå‰©ä½™é‡è¯•æ¬¡æ•°ï¼š{max_retries}ï¼‰")
                    failed_sql = sql
                    return self._retry_query_generation(query, max_retries - 1, failed_sql, error_info, module)
            except Exception as e:
                error_info = str(e)
                st.error(f"SQLæ‰§è¡Œé”™è¯¯: {error_info}")
                if max_retries > 0:
                    st.warning(f"å°†å°è¯•é‡æ–°ç”ŸæˆSQLï¼ˆå‰©ä½™é‡è¯•æ¬¡æ•°ï¼š{max_retries}ï¼‰")
                    failed_sql = sql
                    return self._retry_query_generation(query, max_retries - 1, failed_sql, error_info, module)
                result = []

        # æ£€æŸ¥æŸ¥è¯¢æ˜¯å¦æˆåŠŸå¹¶è¿”å›æœ‰æ•ˆç»“æœ
        query_successful = self.is_valid_query_result(result)

        # æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸåï¼Œç›´æ¥æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
        if query_successful == False:
            return None
        st.subheader("æŸ¥è¯¢ç»“æœæ•°æ®")
        # è½¬æ¢ä¸ºDataFrameå¹¶æ˜¾ç¤º
        df = pd.DataFrame(result)
        st.dataframe(df)  # ç›´æ¥æ˜¾ç¤ºæ•°æ®è¡¨æ ¼

        # æå–SQLä¸­ä½¿ç”¨çš„è¡¨ï¼Œå¹¶è·å–ç›¸å…³çš„schemaä¿¡æ¯
        tables = self.extract_tables_from_sql(sql)
        specific_schema_info = self.get_specific_schema_info(tables)
        # ç”Ÿæˆå›ç­”ï¼Œåªä¼ é€’ç›¸å…³çš„schemaä¿¡æ¯
        messages1 = self.generate_answer_prompt(result, query, sql, specific_schema_info)
        with st.expander("promptä¿¡æ¯ï¼š", expanded=False):
            st.write(messages1)


        st.write("### ç­”æ¡ˆï¼š")
        # åˆ›å»ºä¸€ä¸ªç©ºçš„å®¹å™¨ç”¨äºæ˜¾ç¤ºæµå¼è¾“å‡º
        answer_container = st.empty()
        response_text = ""

        # ä½¿ç”¨æµå¼ä¼ è¾“æ–¹å¼è·å–å›ç­”
        stream = self.client.chat.completions.create(
            model="glm-4-plus",
            messages=messages1,
            stream=True
        )

        # é€æ­¥æ¥æ”¶å¹¶æ˜¾ç¤ºå›ç­”
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                response_text += chunk.choices[0].delta.content
                answer_container.markdown(response_text)

        # æå–å›¾è¡¨é…ç½®
        chart_config = self.extract_chart_config(response_text)

        # åªæœ‰åœ¨æŸ¥è¯¢æˆåŠŸä¸”SQLæ˜¯æ–°ç”Ÿæˆçš„ï¼ˆä¸æ˜¯ä»ç¼“å­˜è·å–çš„ï¼‰æ—¶æ‰å°†SQLä¿å­˜åˆ°ç¼“å­˜
        if query_successful and cached_sql is None:
            self.cache.save_to_cache(
                query,
                self.db_config['database'],
                sql
            )
            st.success("âœ… æŸ¥è¯¢æˆåŠŸï¼ŒSQLå·²ä¿å­˜åˆ°ç¼“å­˜")
        elif not query_successful:
            st.warning("âš ï¸ æŸ¥è¯¢æœªè¿”å›æœ‰æ•ˆç»“æœï¼Œæ­¤æŸ¥è¯¢ä¸ä¼šè¢«ç¼“å­˜")

        # è¿”å›æ–‡æœ¬å›ç­”å’Œå›¾è¡¨é…ç½®
        return response_text, chart_config, result

    def _retry_query_generation(self, query: str, max_retries: int, failed_sql: str = None,
                                error_info: str = None, module: str = None) -> tuple:
        """é‡è¯•ç”ŸæˆSQLæŸ¥è¯¢ï¼ŒåŒ…å«ä¸Šä¸€æ¬¡å¤±è´¥çš„SQLå’Œé”™è¯¯ä¿¡æ¯ï¼Œæ”¯æŒä¸šåŠ¡æ¨¡å—è¿‡æ»¤"""
        if max_retries <= 0:
            st.error("é‡è¯•æ¬¡æ•°å·²ç”¨å®Œï¼Œæ— æ³•ç”ŸæˆSQLæŸ¥è¯¢")
            return None, None, None
        # ã€æ–°å¢ä»£ç ã€‘è·å–schemaä¿¡æ¯ï¼Œä½¿ç”¨æ¨¡å—è¿‡æ»¤
        if module:
            relevant_tables = self.get_tables_by_module(module)
            if relevant_tables:
                schema_info = self.get_schema_info(relevant_tables)
            else:
                schema_info = self.get_schema_info()
        else:
            schema_info = self.get_schema_info()
        # æ·»åŠ æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯åˆ°æç¤ºä¸­
        retry_messages = [
            {"role": "system", "content": """ä½ æ˜¯ä¸€ä¸ªSQLä¸“å®¶ï¼Œè´Ÿè´£å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºSQLæŸ¥è¯¢è¯­å¥ã€‚
                ä¹‹å‰ç”Ÿæˆçš„SQLæŸ¥è¯¢æ‰§è¡Œå¤±è´¥æˆ–è¿”å›ä¸ºç©ºï¼Œè¯·å°è¯•ç”Ÿæˆä¸€ä¸ªæ›´å‡†ç¡®çš„SQLæŸ¥è¯¢ã€‚
                è¯·æ³¨æ„ï¼š
                1. ç›´æ¥è¿”å›SQLè¯­å¥ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–ä¿¡æ¯ã€‚
                2. ç°åœ¨ä½¿ç”¨çš„æ˜¯mysqlæ•°æ®åº“ï¼Œç¡®ä¿SQLè¯­å¥è¯­æ³•æ­£ç¡®
                3. ä½¿ç”¨æä¾›çš„schemaä¿¡æ¯æ„å»ºæŸ¥è¯¢
                4. æ³¨æ„ä½¿ç”¨é€‚å½“çš„è¡¨è¿æ¥å’Œæ¡ä»¶
                5. æŸ¥è¯¢çš„è¡¨å¤´éƒ½éœ€è¦æœ‰ä¸­æ–‡æ³¨é‡Šï¼Œä¸è¦ä½¿ç”¨è¡¨åˆ«å
                6. ç¡®ä¿æŸ¥è¯¢å®‰å…¨ï¼Œé¿å…SQLæ³¨å…¥é£é™©
                7. æ£€æŸ¥è¡¨åå’Œå­—æ®µåæ˜¯å¦æ­£ç¡®ï¼Œç¡®ä¿å®ƒä»¬å­˜åœ¨äºschemaä¸­
                8. è€ƒè™‘å¯èƒ½çš„æ•°æ®ç±»å‹è½¬æ¢é—®é¢˜
                9. ç¡®ä¿WHEREæ¡ä»¶åˆç†ï¼Œä¸ä¼šè¿‡æ»¤æ‰æ‰€æœ‰æ•°æ®"""},
            {"role": "user", "content": f"""
                æ•°æ®åº“Schemaä¿¡æ¯å¦‚ä¸‹ï¼š
                {schema_info}
                è¯·å°†ä»¥ä¸‹é—®é¢˜è½¬æ¢ä¸ºSQLæŸ¥è¯¢è¯­å¥ï¼š
                {query}
                ä¸Šä¸€æ¬¡ç”Ÿæˆçš„SQLæŸ¥è¯¢å¤±è´¥ï¼Œè¯¦æƒ…å¦‚ä¸‹ï¼š
                SQLè¯­å¥: {failed_sql if failed_sql else "æ— "}
                é”™è¯¯ä¿¡æ¯: {error_info if error_info else "æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼Œä½†æ²¡æœ‰è¿”å›æ•°æ®"}
                è¯·åˆ†æä¸Šè¿°é”™è¯¯ï¼Œç”Ÿæˆä¸€ä¸ªæ›´å‡†ç¡®çš„SQLæŸ¥è¯¢ã€‚
                """}
        ]
        with st.expander("é‡è¯•ç”ŸæˆSQLçš„promptä¿¡æ¯ï¼š", expanded=False):
            st.write(retry_messages)

        # ç”Ÿæˆæ–°çš„SQL
        response = self.client.chat.completions.create(
            model="glm-4-plus",
            messages=retry_messages
        )

        # è·å–ç”Ÿæˆçš„SQL
        sql = response.choices[0].message.content.strip()
        sql = self.clean_sql_response(sql)
        st.code(f"é‡è¯•ç”Ÿæˆçš„SQLæŸ¥è¯¢:\n{sql}", language="sql")

        # æ‰§è¡ŒSQLæŸ¥è¯¢
        try:
            result = self.execute_query(sql)

            # å¦‚æœä»ç„¶å¤±è´¥ä¸”è¿˜æœ‰é‡è¯•æ¬¡æ•°ï¼Œç»§ç»­é‡è¯•
            if not self.is_valid_query_result(result) and max_retries > 1:
                st.warning(f"é‡è¯•ç”Ÿæˆçš„SQLæ‰§è¡Œä»ç„¶å¤±è´¥æˆ–è¿”å›ä¸ºç©ºï¼Œå°†ç»§ç»­é‡è¯•ï¼ˆå‰©ä½™é‡è¯•æ¬¡æ•°ï¼š{max_retries - 1}ï¼‰")
                return self._retry_query_generation(query, max_retries - 1, sql, None)
            elif max_retries <= 0:
                st.error("é‡è¯•ç”ŸæˆSQLæ¬¡æ•°å·²ç”¨å®Œï¼Œæ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„SQL")
                return None, None, None
        except Exception as e:
            #  TODO error_infoç›®å‰æ— æ³•æºå¸¦ï¼Œå¾…æ”¹è¿›
            error_info = str(e)
            st.error(f"é‡è¯•SQLæ‰§è¡Œé”™è¯¯: {error_info}")
            if max_retries > 1:
                st.warning(f"å°†ç»§ç»­é‡è¯•ï¼ˆå‰©ä½™é‡è¯•æ¬¡æ•°ï¼š{max_retries - 1}ï¼‰")
                return self._retry_query_generation(query, max_retries - 1, sql, error_info)
            elif max_retries <= 0:
                st.error("é‡è¯•ç”ŸæˆSQLæ¬¡æ•°å·²ç”¨å®Œï¼Œæ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„SQL")
                return None, None, None
            result = []

        # æ£€æŸ¥æŸ¥è¯¢æ˜¯å¦æˆåŠŸå¹¶è¿”å›æœ‰æ•ˆç»“æœ
        query_successful = self.is_valid_query_result(result)

        # æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸåï¼Œç›´æ¥æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
        if query_successful == False:
            return None
        st.subheader("æŸ¥è¯¢ç»“æœæ•°æ®")
        # è½¬æ¢ä¸ºDataFrameå¹¶æ˜¾ç¤º
        df = pd.DataFrame(result)
        st.dataframe(df)  # ç›´æ¥æ˜¾ç¤ºæ•°æ®è¡¨æ ¼

        response_text = ""
        chart_config = ""


        # åªæœ‰åœ¨æŸ¥è¯¢æˆåŠŸæ—¶æ‰å°†SQLä¿å­˜åˆ°ç¼“å­˜
        if query_successful:
            # ç”Ÿæˆå›ç­”
            # æå–SQLä¸­ä½¿ç”¨çš„è¡¨ï¼Œå¹¶è·å–ç›¸å…³çš„schemaä¿¡æ¯
            tables = self.extract_tables_from_sql(sql)
            specific_schema_info = self.get_specific_schema_info(tables)
            messages1 = self.generate_answer_prompt(result, query, sql, specific_schema_info)
            with st.expander("promptä¿¡æ¯ï¼š", expanded=False):
                st.write(messages1)
            # response1 = self.client.chat.completions.create(
            #     model="glm-4-plus",
            #     messages=messages1
            # )

            st.write("### ç­”æ¡ˆï¼š")
            # åˆ›å»ºä¸€ä¸ªç©ºçš„å®¹å™¨ç”¨äºæ˜¾ç¤ºæµå¼è¾“å‡º
            answer_container = st.empty()

            # ä½¿ç”¨æµå¼ä¼ è¾“æ–¹å¼è·å–å›ç­”
            stream = self.client.chat.completions.create(
                model="glm-4-plus",
                messages=messages1,
                stream=True
            )

            # é€æ­¥æ¥æ”¶å¹¶æ˜¾ç¤ºå›ç­”
            for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    response_text += chunk.choices[0].delta.content
                    answer_container.markdown(response_text)


            chart_config = self.extract_chart_config(response_text)
            self.cache.save_to_cache(
                query,
                self.db_config['database'],
                sql
            )
            st.success("âœ… é‡è¯•æŸ¥è¯¢æˆåŠŸï¼ŒSQLå·²ä¿å­˜åˆ°ç¼“å­˜")
        else:
            st.warning("âš ï¸ æ‰€æœ‰é‡è¯•éƒ½æœªè¿”å›æœ‰æ•ˆç»“æœï¼Œæ­¤æŸ¥è¯¢ä¸ä¼šè¢«ç¼“å­˜")

        return response_text, chart_config, result
    def display_result(self, markdown_text, chart_config=None, query_result=None):
        with st.expander("è¿”å›çš„å…¨æ–‡ï¼š", expanded=False):
            st.write(markdown_text)
        # å¦‚æœæœ‰å›¾è¡¨é…ç½®ï¼Œæ˜¾ç¤ºå›¾è¡¨
        if chart_config and 'charts' in chart_config and query_result:
            self.display_charts(chart_config, query_result)

    def get_tables_by_module(self, module):
        """ä»sys_tables.dbè·å–æŒ‡å®šæ¨¡å—çš„è¡¨ååˆ—è¡¨"""
        try:
            # è¿æ¥sys_tables.dbæ•°æ®åº“
            sys_conn = sqlite3.connect("./sys_tables.db")
            sys_cursor = sys_conn.cursor()

            # æŸ¥è¯¢æŒ‡å®šæ¨¡å—çš„æ‰€æœ‰è¡¨
            sys_cursor.execute(
                "SELECT table_name, description FROM system_tables WHERE module = ?",
                (module,)
            )

            # è·å–è¡¨åå’Œæè¿°
            tables_info = sys_cursor.fetchall()
            # ç¡®ä¿å®Œå…¨æ¶ˆè´¹ç»“æœé›†
            sys_cursor.fetchall()
            
            sys_conn.close()

            if tables_info:
                st.success(f"âœ… ä»æ¨¡å— '{module}' ä¸­æ‰¾åˆ° {len(tables_info)} ä¸ªç›¸å…³è¡¨")
                return [row[0] for row in tables_info]
            else:
                st.warning(f"âš ï¸ åœ¨æ¨¡å— '{module}' ä¸­æœªæ‰¾åˆ°ä»»ä½•è¡¨")
                return []
        except Exception as e:
            st.error(f"è·å–æ¨¡å—è¡¨ä¿¡æ¯å¤±è´¥: {str(e)}")
            return []

    def clean_json_comments(self, json_str):
        """
        æ¸…æ´—JSONå­—ç¬¦ä¸²ä¸­çš„æ³¨é‡Š

        Args:
            json_str (str): å¯èƒ½åŒ…å«æ³¨é‡Šçš„JSONå­—ç¬¦ä¸²

        Returns:
            str: æ¸…æ´—åçš„JSONå­—ç¬¦ä¸²ï¼Œç§»é™¤äº†æ‰€æœ‰æ³¨é‡Š
        """
        import re

        # ç§»é™¤å•è¡Œæ³¨é‡Š (// åé¢çš„å†…å®¹)
        cleaned_str = re.sub(r'//.*?(\n|$)', r'\1', json_str)

        # ç§»é™¤å¤šè¡Œæ³¨é‡Š (/* ... */ æ ¼å¼)
        cleaned_str = re.sub(r'/\*.*?\*/', '', cleaned_str, flags=re.DOTALL)

        # ç§»é™¤è¡Œå°¾ç©ºç™½
        cleaned_str = re.sub(r'\s+$', '', cleaned_str, flags=re.MULTILINE)

        # å¤„ç†å¯èƒ½å‡ºç°çš„è¿ç»­ç©ºè¡Œ
        cleaned_str = re.sub(r'\n\s*\n', '\n', cleaned_str)

        return cleaned_str


    def display_charts(self, chart_config, query_result):
        """æ˜¾ç¤ºå›¾è¡¨ï¼Œæ”¯æŒå¤šç§å›¾è¡¨ç±»å‹"""
        df = pd.DataFrame(query_result)

        for chart in chart_config.get('charts', []):
            chart_type = chart.get('type')
            title = chart.get('title', 'æ•°æ®å¯è§†åŒ–')

            st.subheader(title)
            if chart.get('description'):
                st.write(chart.get('description'))

            # ä½¿ç”¨é…ç½®ä¸­çš„æ•°æ®
            data = chart.get('data', {})
            labels = data.get('labels', [])
            values = data.get('values', [])

            # é¥¼å›¾
            if chart_type == 'pie':
                fig = px.pie(
                    names=labels,
                    values=values,
                    title=title,
                    hole=data.get('hole', 0),  # æ”¯æŒç¯å½¢å›¾
                    color_discrete_sequence=data.get('colors')  # è‡ªå®šä¹‰é¢œè‰²
                )
                st.plotly_chart(fig, use_container_width=True)

            # æ ‘çŠ¶å›¾
            elif chart_type == 'treemap':
                parents = data.get('parents', [''] * len(labels))
                fig = px.treemap(
                    names=labels,
                    values=values,
                    parents=parents,
                    title=title,
                    color_discrete_sequence=data.get('colors')
                )
                st.plotly_chart(fig, use_container_width=True)

            # æŸ±çŠ¶å›¾
            elif chart_type == 'bar':
                # æ”¯æŒæ°´å¹³å’Œå‚ç›´æŸ±çŠ¶å›¾
                orientation = data.get('orientation', 'v')  # 'v'ä¸ºå‚ç›´ï¼Œ'h'ä¸ºæ°´å¹³

                if orientation == 'h':
                    fig = px.bar(
                        y=labels,
                        x=values,
                        title=title,
                        orientation='h',
                        color=data.get('color_by'),  # æŒ‰ç±»åˆ«ç€è‰²
                        color_discrete_sequence=data.get('colors'),
                        text_auto=data.get('show_values', True)  # æ˜¾ç¤ºæ•°å€¼
                    )
                else:
                    fig = px.bar(
                        x=labels,
                        y=values,
                        title=title,
                        color=data.get('color_by'),
                        color_discrete_sequence=data.get('colors'),
                        text_auto=data.get('show_values', True)
                    )

                # è®¾ç½®æ¡å½¢å›¾æ ·å¼
                if data.get('is_grouped', False):
                    # åˆ†ç»„æŸ±çŠ¶å›¾
                    fig.update_layout(barmode='group')
                elif data.get('is_stacked', False):
                    # å †å æŸ±çŠ¶å›¾
                    fig.update_layout(barmode='stack')

                st.plotly_chart(fig, use_container_width=True)

            # æŠ˜çº¿å›¾
            elif chart_type == 'line':
                # å¤„ç†å¤šæ¡æŠ˜çº¿çš„æƒ…å†µ
                if 'series' in data:
                    series_data = data.get('series', [])
                    fig = go.Figure()

                    for series in series_data:
                        fig.add_trace(go.Scatter(
                            x=series.get('x', labels),
                            y=series.get('y', []),
                            mode='lines+markers' if data.get('show_markers', True) else 'lines',
                            name=series.get('name', ''),
                            line=dict(width=series.get('line_width', 2))
                        ))
                else:
                    # å•æ¡æŠ˜çº¿
                    fig = px.line(
                        x=labels,
                        y=values,
                        title=title,
                        markers=data.get('show_markers', True),
                        line_shape=data.get('line_shape', 'linear')  # linear, spline, hv, vh, hvh, vhv
                    )

                # è®¾ç½®åæ ‡è½´æ ‡é¢˜
                fig.update_layout(
                    xaxis_title=data.get('x_axis_title', ''),
                    yaxis_title=data.get('y_axis_title', '')
                )

                st.plotly_chart(fig, use_container_width=True)

            # æ•£ç‚¹å›¾
            elif chart_type == 'scatter':
                # è·å–ç¬¬ä¸‰ç»´åº¦æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
                sizes = data.get('sizes', None)
                color_values = data.get('color_values', None)

                fig = px.scatter(
                    x=data.get('x', labels),
                    y=data.get('y', values),
                    size=sizes,  # æ°”æ³¡å¤§å°ï¼ˆå¯é€‰ï¼‰
                    color=color_values,  # é¢œè‰²ç»´åº¦ï¼ˆå¯é€‰ï¼‰
                    title=title,
                    hover_name=data.get('hover_names'),  # æ‚¬åœæ˜¾ç¤ºçš„æ ‡ç­¾
                    size_max=data.get('size_max', 20),  # æœ€å¤§æ°”æ³¡å¤§å°
                    opacity=data.get('opacity', 0.7)  # é€æ˜åº¦
                )

                st.plotly_chart(fig, use_container_width=True)

            # é¢ç§¯å›¾
            elif chart_type == 'area':
                fig = px.area(
                    x=labels,
                    y=values,
                    title=title,
                    color_discrete_sequence=data.get('colors')
                )

                # è®¾ç½®æ˜¯å¦å †å 
                if not data.get('is_stacked', True):
                    fig.update_layout(groupnorm='fraction')  # ç™¾åˆ†æ¯”å †å 

                st.plotly_chart(fig, use_container_width=True)

            # çƒ­åŠ›å›¾
            elif chart_type == 'heatmap':
                # çƒ­åŠ›å›¾éœ€è¦äºŒç»´æ•°æ®
                z_values = data.get('z_values', [])  # çƒ­åŠ›å€¼
                x_labels = data.get('x_labels', labels)  # xè½´æ ‡ç­¾
                y_labels = data.get('y_labels', [])  # yè½´æ ‡ç­¾

                fig = px.imshow(
                    z_values,
                    x=x_labels,
                    y=y_labels,
                    color_continuous_scale=data.get('color_scale', 'Viridis'),
                    title=title
                )

                # æ˜¾ç¤ºæ•°å€¼
                if data.get('show_values', True):
                    fig.update_traces(text=z_values, texttemplate="%{text}")

                st.plotly_chart(fig, use_container_width=True)

            # é›·è¾¾å›¾
            elif chart_type == 'radar':
                # é›·è¾¾å›¾ç‰¹æ®Šå¤„ç†
                categories = labels

                # å¤„ç†å¤šä¸ªé›·è¾¾ç³»åˆ—
                if 'series' in data:
                    series_data = data.get('series', [])
                    fig = go.Figure()

                    for series in series_data:
                        fig.add_trace(go.Scatterpolar(
                            r=series.get('values', []),
                            theta=categories,
                            fill='toself',
                            name=series.get('name', '')
                        ))
                else:
                    # å•ä¸ªé›·è¾¾ç³»åˆ—
                    fig = go.Figure(go.Scatterpolar(
                        r=values,
                        theta=categories,
                        fill='toself'
                    ))

                fig.update_layout(
                    polar=dict(
                        radialaxis=dict(
                            visible=True,
                            range=[0, data.get('max_value', None)]
                        )
                    ),
                    title=title
                )

                st.plotly_chart(fig, use_container_width=True)

            # ç®±çº¿å›¾
            elif chart_type == 'box':
                fig = px.box(
                    x=data.get('group_by', None),  # åˆ†ç»„å˜é‡
                    y=values,
                    title=title,
                    points=data.get('show_points', 'outliers')  # all, outliers, False
                )

                st.plotly_chart(fig, use_container_width=True)

            # æ¼æ–—å›¾
            elif chart_type == 'funnel':
                fig = go.Figure(go.Funnel(
                    y=labels,
                    x=values,
                    textinfo=data.get('text_info', 'value+percent')
                ))

                fig.update_layout(title=title)
                st.plotly_chart(fig, use_container_width=True)

            # ç€‘å¸ƒå›¾
            elif chart_type == 'waterfall':
                measure = data.get('measures', ['relative'] * len(labels))

                fig = go.Figure(go.Waterfall(
                    name=title,
                    orientation='v',
                    measure=measure,
                    x=labels,
                    y=values,
                    connector={"line": {"color": "rgb(63, 63, 63)"}},
                ))

                fig.update_layout(title=title)
                st.plotly_chart(fig, use_container_width=True)

            # å¦‚æœæ˜¯æœªçŸ¥çš„å›¾è¡¨ç±»å‹ï¼Œæ˜¾ç¤ºè­¦å‘Š
            else:
                st.warning(f"ä¸æ”¯æŒçš„å›¾è¡¨ç±»å‹: {chart_type}")



def init_session_state():
    """åˆå§‹åŒ–session stateå˜é‡"""
    if 'query_system' not in st.session_state:
        st.session_state.query_system = None
    if 'cache_system' not in st.session_state:
        st.session_state.cache_system = SemanticQueryCache()
    if 'similarity_threshold' not in st.session_state:
        st.session_state.similarity_threshold = 0.85


def create_query_system(db_config: Dict, api_key: str):
    """åˆ›å»ºæŸ¥è¯¢ç³»ç»Ÿå®ä¾‹"""
    try:
        # ä½¿ç”¨å…¨å±€ç¼“å­˜ç³»ç»Ÿ
        cache_system = st.session_state.cache_system
        # æ›´æ–°ç›¸ä¼¼åº¦é˜ˆå€¼
        cache_system.similarity_threshold = st.session_state.similarity_threshold

        # åˆ›å»ºæŸ¥è¯¢ç³»ç»Ÿ
        query_system = NLDatabaseQuery(db_config, api_key, cache_system)
        st.session_state.query_system = query_system
        return query_system
    except Exception as e:
        st.error(f"åˆ›å»ºæŸ¥è¯¢ç³»ç»Ÿå¤±è´¥: {str(e)}")
        return None
def get_all_modules():
    """è·å–æ‰€æœ‰ä¸šåŠ¡æ¨¡å—"""
    try:
        conn = sqlite3.connect("./sys_tables.db")
        cursor = conn.cursor()
        cursor.execute("SELECT DISTINCT module FROM system_tables ORDER BY module")
        modules = [row[0] for row in cursor.fetchall()]
        conn.close()
        return modules
    except Exception as e:
        st.error(f"è·å–ä¸šåŠ¡æ¨¡å—å¤±è´¥: {str(e)}")
        return []

def main():
    st.set_page_config(page_title="SmartDBChat - è‡ªç„¶è¯­è¨€æ•°æ®åº“æŸ¥è¯¢", layout="wide")

    # åˆå§‹åŒ–session state
    init_session_state()

    # åˆå§‹åŒ–æ¨¡å—é€‰æ‹©çŠ¶æ€
    if 'selected_module' not in st.session_state:
        st.session_state.selected_module = None

    st.title("SmartDBChat - è‡ªç„¶è¯­è¨€æ•°æ®åº“æŸ¥è¯¢")

    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("é…ç½®")

        # æ•°æ®åº“é…ç½®
        st.subheader("æ•°æ®åº“è®¾ç½®")
        host = st.text_input("ä¸»æœº", value="localhost")
        port = st.number_input("ç«¯å£", value=3306)
        user = st.text_input("ç”¨æˆ·å", value="root")
        password = st.text_input("å¯†ç ", type="password", value="")
        database = st.text_input("æ•°æ®åº“å", value="")

        # APIé…ç½®
        st.subheader("APIè®¾ç½®")
        api_key = st.text_input("æ™ºè°±AI APIå¯†é’¥", type="password", value="")

        # ç¼“å­˜é…ç½®
        st.subheader("ç¼“å­˜è®¾ç½®")
        similarity_threshold = st.slider(
            "ç›¸ä¼¼åº¦é˜ˆå€¼",
            min_value=0.5,
            max_value=1.0,
            value=st.session_state.similarity_threshold,
            step=0.05,
            help="è®¾ç½®æŸ¥è¯¢ç›¸ä¼¼åº¦åŒ¹é…çš„é˜ˆå€¼ï¼Œå€¼è¶Šé«˜è¦æ±‚åŒ¹é…è¶Šç²¾ç¡®"
        )
        st.session_state.similarity_threshold = similarity_threshold

        # è¿æ¥æŒ‰é’®
        if st.button("è¿æ¥æ•°æ®åº“"):
            db_config = {
                'host': host,
                'port': int(port),
                'user': user,
                'password': password,
                'database': database
            }

            if not api_key:
                st.error("è¯·è¾“å…¥æ™ºè°±AI APIå¯†é’¥")
            else:
                with st.spinner("æ­£åœ¨è¿æ¥æ•°æ®åº“..."):
                    query_system = create_query_system(db_config, api_key)
                    if query_system:
                        st.success("æ•°æ®åº“è¿æ¥æˆåŠŸï¼")
        # ã€æ–°å¢ä»£ç ã€‘æ·»åŠ æ¨¡å—é€‰æ‹©
        if st.session_state.query_system:
            st.subheader("ä¸šåŠ¡æ¨¡å—è¿‡æ»¤")
            # è·å–æ‰€æœ‰ä¸šåŠ¡æ¨¡å—
            modules = get_all_modules()
            selected_module = st.selectbox(
                "é€‰æ‹©ä¸šåŠ¡æ¨¡å—",
                ["å…¨éƒ¨"] + modules,
                help="é€‰æ‹©ä¸šåŠ¡æ¨¡å—å¯ä»¥å‡å°‘LLMå¤„ç†çš„è¡¨æ•°é‡ï¼Œæé«˜ç”ŸæˆSQLçš„å‡†ç¡®æ€§"
            )

            if selected_module == "å…¨éƒ¨":
                st.session_state.selected_module = None
            else:
                st.session_state.selected_module = selected_module

        # ç¼“å­˜ç®¡ç†
        if st.session_state.cache_system:
            st.subheader("ç¼“å­˜ç®¡ç†")

            cache_stats = st.session_state.cache_system.get_cache_stats()
            st.write(f"ç¼“å­˜æ¡ç›®æ•°: {cache_stats['total_entries']}")
            st.write(f"ç¼“å­˜å‘½ä¸­æ¬¡æ•°: {cache_stats['total_hits']}")

            if st.button("æ¸…ç©ºç¼“å­˜"):
                message = st.session_state.cache_system.clear_cache()
                st.success(message)

    # ä¸»ç•Œé¢
    if st.session_state.query_system:
        # æŸ¥è¯¢è¾“å…¥åŒºåŸŸ
        query = st.text_area("è¯·è¾“å…¥ä½ çš„é—®é¢˜", height=100)

        # æ·»åŠ é‡è¯•æ¬¡æ•°å’Œå½“å‰é€‰æ‹©çš„æ¨¡å—æ˜¾ç¤º
        col1, col2, col3 = st.columns([2, 2, 1])
        with col1:
            if st.session_state.selected_module:
                st.info(f"å½“å‰ä¸šåŠ¡æ¨¡å—: {st.session_state.selected_module}")
            else:
                st.info("å½“å‰æŸ¥è¯¢èŒƒå›´: æ‰€æœ‰è¡¨")

        with col3:
            max_retries = st.number_input("æœ€å¤§é‡è¯•æ¬¡æ•°", min_value=0, max_value=5, value=2,
                                          help="å¦‚æœSQLæŸ¥è¯¢å¤±è´¥æˆ–è¿”å›ä¸ºç©ºï¼Œè‡ªåŠ¨é‡è¯•ç”ŸæˆSQLçš„æœ€å¤§æ¬¡æ•°")

        if st.button("æŸ¥è¯¢") and query:
            with st.spinner("æ­£åœ¨å¤„ç†æŸ¥è¯¢..."):
                try:
                    # ä¼ å…¥é€‰æ‹©çš„æ¨¡å—
                    module = st.session_state.selected_module
                    markdown_text, chart_config, query_result = st.session_state.query_system.natural_language_query(
                        query, module=module, max_retries=max_retries)

                    # æ˜¾ç¤ºç»“æœ
                    if markdown_text and query_result:
                        st.session_state.query_system.display_result(markdown_text, chart_config, query_result)
                    else:
                        st.error("æŸ¥è¯¢æœªè¿”å›æœ‰æ•ˆç»“æœ")
                except Exception as e:
                    st.error(f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}")
    else:
        st.info("è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½®å¹¶è¿æ¥æ•°æ®åº“")


if __name__ == "__main__":
    main()
